{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameter:\n",
    "    def __init__(self):\n",
    "        self.input_nodes=32*64\n",
    "        self.layer=3\n",
    "        self.layer_nodes=[256,16,1]\n",
    "        self.learning_rate=0.005\n",
    "        self.activation_function_name='leaky_ReLU'\n",
    "        self.epoch=10\n",
    "        self.batchsize=4\n",
    "        self.loss_function_name='cross_entropy'\n",
    "    def show(self):\n",
    "        print('input_nodes=',self.input_nodes)\n",
    "        print('layer=',self.layer)\n",
    "        print('layer_nodes=',self.layer_nodes)\n",
    "        print('learning_rate=',self.learning_rate)\n",
    "        print('activation_function_name=',self.activation_function_name)\n",
    "        print()\n",
    "        print('epoch=',self.epoch)\n",
    "        print('batchsize=',self.batchsize)\n",
    "        print('loss_function_name=',self.loss_function_name)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(x,activationfunctionname):\n",
    "    if activationfunctionname=='sigmoid':\n",
    "        return 1/(1+numpy.exp(-x))\n",
    "    if activationfunctionname=='tanh':\n",
    "        return (numpy.exp(x)-numpy.exp(-x))/(numpy.exp(x)+numpy.exp(-x))\n",
    "    if activationfunctionname=='ReLU':\n",
    "        return numpy.maximum(0,x)\n",
    "    if activationfunctionname=='leaky_ReLU':\n",
    "        return numpy.maximum(0.01*x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_prime(x,activationfunctionname):\n",
    "    if activationfunctionname=='sigmoid':\n",
    "        return activation_function(x,'sigmoid')*(1-activation_function(x,'sigmoid'))\n",
    "    if activationfunctionname=='tanh':\n",
    "        return 1-activation_function(x,'tanh')*activation_function(x,'tanh')\n",
    "    if activationfunctionname=='ReLU':\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=0\n",
    "        return x\n",
    "    if activationfunctionname=='leaky_ReLU':\n",
    "        x[x>=0]=1\n",
    "        x[x<0]=0.01\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y,yt,lossfunctionname):\n",
    "    if lossfunctionname=='cross_entropy':\n",
    "        return -(yt*numpy.log(y)+(1-yt)*numpy.log(1-y))\n",
    "    if lossfunctionname=='squared':\n",
    "        return (y-yt)*(y-yt)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,parameter):\n",
    "        self.input_nodes=parameter.input_nodes\n",
    "        self.layer=parameter.layer\n",
    "        self.layer_nodes=parameter.layer_nodes\n",
    "        self.w=[numpy.random.normal(0,1,(self.layer_nodes[0],self.input_nodes))]\n",
    "        self.b=[numpy.array(numpy.random.normal(0,1,(self.layer_nodes[0],1)),ndmin=2)]\n",
    "        self.mean=numpy.zeros((self.input_nodes,1))\n",
    "        self.var=numpy.ones((self.input_nodes,1))\n",
    "        for i in range(1,self.layer):\n",
    "            self.w.append(numpy.random.normal(0,1,(self.layer_nodes[i],self.layer_nodes[i-1])))\n",
    "            self.b.append(numpy.array(numpy.random.normal(0,1,(self.layer_nodes[i],1)),ndmin=2))\n",
    "        self.activation_function_name=parameter.activation_function_name\n",
    "    def forward_propagation(self,inputlist):\n",
    "        outputs=numpy.array(inputlist,ndmin=2)\n",
    "        outputs=(outputs-self.mean)/numpy.sqrt(self.var+0.01)\n",
    "        for i in range(0,self.layer-1):\n",
    "            inputs=numpy.dot(self.w[i],outputs)+numpy.array(self.b[i],ndmin=2).reshape(-1,1)\n",
    "            outputs=activation_function(inputs,self.activation_function_name)\n",
    "        inputs=numpy.dot(self.w[self.layer-1],outputs)+numpy.array(self.b[self.layer-1],ndmin=2).reshape(-1,1)\n",
    "        outputs=activation_function(inputs,'sigmoid')\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_test(nn,test_x,test_y,parameter):\n",
    "    batchsize=parameter.batchsize\n",
    "    num_batch=int(test_x.shape[1]/batchsize)\n",
    "    total_num=num_batch*batchsize\n",
    "    error=0\n",
    "    e0=0\n",
    "    e1=0\n",
    "    t0=0\n",
    "    for i in range(0,num_batch):\n",
    "        x=test_x[:,i*batchsize:(i+1)*batchsize]\n",
    "        yt=test_y[:,i*batchsize:(i+1)*batchsize]\n",
    "        y=nn.forward_propagation(x)\n",
    "        for j in range(0,batchsize):\n",
    "            if y[0][j]<0.5:\n",
    "                y[0][j]=0\n",
    "            elif y[0][j]>0.5:\n",
    "                y[0][j]=1\n",
    "        dy=y-yt            \n",
    "        for j in range(0,batchsize):\n",
    "            if yt[0][j]==0:\n",
    "                t0+=1\n",
    "            if dy[0][j]!=0:\n",
    "                error=error+1\n",
    "                if yt[0][j]==0:\n",
    "                    e0+=1\n",
    "                else:\n",
    "                    e1+=1\n",
    "    print('背景误判率',round(100*e0/t0,2),'%:（',e0,'/',t0,'）  对象误判率',round(100*e1/(total_num-t0),2),'%:（',e1,'/',total_num-t0,'）')\n",
    "    print(total_num,'个测试样本中错误',error,'个，错误率为',round(100*error/total_num,2),'%.')\n",
    "    return 100*error/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nn,train_x,train_y,test_x,test_y,parameter):\n",
    "    batchsize=parameter.batchsize\n",
    "    num_batch=int(train_x.shape[1]/batchsize)\n",
    "    for i in range(0,nn.input_nodes):\n",
    "        nn.mean[i]=numpy.mean(train_x[i])\n",
    "        nn.var[i]=numpy.var(train_x[i])\n",
    "    for i in range(0,parameter.epoch):\n",
    "        print('开始训练第 ',i+1,' 轮,每轮 ',num_batch,'批')\n",
    "        cost_time=time.time()\n",
    "        for j in range(0,num_batch):\n",
    "            trainx=train_x[:,j*batchsize:(j+1)*batchsize]\n",
    "            trianx=(trainx-nn.mean)/numpy.sqrt(nn.var+0.01)\n",
    "            trainy=train_y[:,j*batchsize:(j+1)*batchsize]\n",
    "            if parameter.loss_function_name=='cross_entropy':\n",
    "                z=[numpy.dot(nn.w[0],trainx)+numpy.array(nn.b[0],ndmin=2).reshape(-1,1)]\n",
    "                a=[activation_function(z[0],nn.activation_function_name)]\n",
    "                for k in range(1,nn.layer-1):\n",
    "                    z.append(numpy.dot(nn.w[k],a[k-1])+numpy.array(nn.b[k],ndmin=2).reshape(-1,1))\n",
    "                    a.append(activation_function(z[k],nn.activation_function_name))\n",
    "                z.append(numpy.dot(nn.w[nn.layer-1],a[nn.layer-2])+nn.b[nn.layer-1])\n",
    "                a.append(activation_function(z[nn.layer-1],'sigmoid'))\n",
    "            else:\n",
    "                print('没有此损失函数的反向计算')\n",
    "                return\n",
    "            dz=[a[nn.layer-1]-trainy]\n",
    "            dw=[numpy.dot(dz[0],a[nn.layer-2].T)/batchsize]\n",
    "            db=[numpy.sum(dz[0],axis=1,keepdims=True)]\n",
    "            for k in range(1,nn.layer-1):\n",
    "                dz.append(numpy.dot(nn.w[nn.layer-k].T,dz[k-1])*activation_prime(z[nn.layer-k-1],nn.activation_function_name))\n",
    "                dw.append(numpy.dot(dz[k],a[nn.layer-k-2].T)/batchsize)\n",
    "                db.append(numpy.sum(dz[k],axis=1,keepdims=True))\n",
    "            dz.append(numpy.dot(nn.w[1].T,dz[nn.layer-2])*activation_prime(z[0],nn.activation_function_name))\n",
    "            dw.append(numpy.dot(dz[nn.layer-1],trainx.T)/batchsize)\n",
    "            db.append(numpy.sum(dz[nn.layer-1],axis=1,keepdims=True))\n",
    "            for k in range(0,nn.layer-1):\n",
    "                nn.w[k]-=parameter.learning_rate*dw[nn.layer-k-1]\n",
    "                nn.b[k]=numpy.array(nn.b[k],ndmin=2).reshape(-1,1)-parameter.learning_rate*db[nn.layer-k-1]\n",
    "        cost_time=time.time()-cost_time\n",
    "        print('已完成',i+1,'/',parameter.epoch,' 本轮用时',round(cost_time,2),'秒')\n",
    "        error_test(nn,test_x,test_y,parameter)\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savenn(nn,file_name):\n",
    "    os.mkdir(file_name)\n",
    "    para=numpy.array([nn.input_nodes,nn.layer])\n",
    "    numpy.savetxt(file_name+'/parameter',para)\n",
    "    layer=numpy.array(nn.layer_nodes)\n",
    "    numpy.savetxt(file_name+'/layer',layer)\n",
    "    f=open(file_name+'/af','w')\n",
    "    f.write(nn.activation_function_name)\n",
    "    f.close()\n",
    "    mv=[]\n",
    "    mv.append(nn.mean.flatten())\n",
    "    mv.append(nn.var.flatten())\n",
    "    mv=numpy.array(mv)\n",
    "    numpy.savetxt(file_name+'/mv',mv)\n",
    "    for i in range(0,nn.layer):\n",
    "        numpy.savetxt(file_name+'/w'+str(i),nn.w[i])\n",
    "        numpy.savetxt(file_name+'/b'+str(i),nn.b[i])\n",
    "        \n",
    "    print('保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadnn(file_name):\n",
    "    para=parameter()\n",
    "    f=numpy.loadtxt(file_name+'/parameter')\n",
    "    para.input_nodes=int(f[0])\n",
    "    para.layer=int(f[1])\n",
    "    f=numpy.loadtxt(file_name+'/layer')\n",
    "    para.layer_nodes=[]\n",
    "    for i in range(0,para.layer):\n",
    "        para.layer_nodes.append(int(f[i]))\n",
    "    f=open(file_name+'/af')\n",
    "    para.activation_function_name=f.read()\n",
    "    f.close()\n",
    "    nn=NeuralNetwork(para)\n",
    "    for i in range(0,nn.layer):\n",
    "        nn.w[i]=numpy.array(numpy.loadtxt(file_name+'/w'+str(i)),ndmin=2)\n",
    "        nn.b[i]=numpy.array(numpy.loadtxt(file_name+'/b'+str(i)),ndmin=2)\n",
    "    f=numpy.loadtxt(file_name+'/mv')\n",
    "    nn.mean=f[0,:]\n",
    "    nn.var=f[1,:]\n",
    "    nn.mean=numpy.array(nn.mean,ndmin=2).T\n",
    "    nn.var=numpy.array(nn.var,ndmin=2).T\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_train_set(path_1,path_0):\n",
    "    tx=[]\n",
    "    ty=[]\n",
    "    \n",
    "    path=path_1\n",
    "    x_dirs=os.listdir(path)\n",
    "    for x_file in x_dirs:\n",
    "        fpath=os.path.join(path,x_file)\n",
    "        file=Image.open(fpath).convert('L')\n",
    "        x=file.resize((32,64))\n",
    "        x=numpy.array(x)\n",
    "        x=x.flatten()\n",
    "        tx.append(x)\n",
    "        ty.append([1])\n",
    "        \n",
    "    path=path_0\n",
    "    x_dirs=os.listdir(path)\n",
    "    for x_file in x_dirs:\n",
    "        fpath=os.path.join(path,x_file)\n",
    "        file=Image.open(fpath).convert('L')\n",
    "        x=file.crop((0,0,320,480))\n",
    "        x=x.resize((32,64))\n",
    "        x=numpy.array(x)\n",
    "        x=x.flatten()\n",
    "        tx.append(x)\n",
    "        ty.append([0])\n",
    "        x=file.crop((320,0,640,480))\n",
    "        x=x.resize((32,64))\n",
    "        x=numpy.array(x)\n",
    "        x=x.flatten()\n",
    "        tx.append(x)\n",
    "        ty.append([0])\n",
    "    tx=numpy.array(tx)\n",
    "    ty=numpy.array(ty)\n",
    "    num=tx.shape[0]\n",
    "    index=numpy.arange(num)\n",
    "    numpy.random.shuffle(index)\n",
    "    ttx=tx[index]\n",
    "    tty=ty[index]\n",
    "    tx=ttx[:num-1024,:]\n",
    "    ty=tty[:num-1024,:]\n",
    "    ttx=ttx[num-1024:,:]\n",
    "    tty=tty[num-1024:,:]\n",
    "    set=[tx,ty,ttx,tty]\n",
    "    print('集合划分完成')\n",
    "    return set\n",
    "def obtain_car_train_set(path_1,path_0):\n",
    "    tx=[]\n",
    "    ty=[]\n",
    "    \n",
    "    path=path_1\n",
    "    x_dirs=os.listdir(path)\n",
    "    for x_file in x_dirs:\n",
    "        fpath=os.path.join(path,x_file)\n",
    "        file=Image.open(fpath).convert('L')\n",
    "        x=file.resize((32,64))\n",
    "        x=numpy.array(x)\n",
    "        x=x.flatten()\n",
    "        tx.append(x)\n",
    "        ty.append([1])\n",
    "        \n",
    "    path=path_0\n",
    "    x_dirs=os.listdir(path)\n",
    "    for x_file in x_dirs:\n",
    "        fpath=os.path.join(path,x_file)\n",
    "        file=Image.open(fpath).convert('L')\n",
    "        x=file.resize((32,64))\n",
    "        x=numpy.array(x)\n",
    "        x=x.flatten()\n",
    "        tx.append(x)\n",
    "        ty.append([0])\n",
    "    tx=numpy.array(tx)\n",
    "    ty=numpy.array(ty)\n",
    "    num=tx.shape[0]\n",
    "    index=numpy.arange(num)\n",
    "    numpy.random.shuffle(index)\n",
    "    ttx=tx[index]\n",
    "    tty=ty[index]\n",
    "    tx=ttx[:num-100,:]\n",
    "    ty=tty[:num-100,:]\n",
    "    ttx=ttx[num-100:,:]\n",
    "    tty=tty[num-100:,:]\n",
    "    set=[tx,ty,ttx,tty]\n",
    "    print('集合划分完成')\n",
    "    return set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合划分完成\n"
     ]
    }
   ],
   "source": [
    "#开始训练人的分类器\n",
    "[train_x,train_y,test_x,test_y]=obtain_train_set('./data/Pedestrians/48x96','./data/NonPedestrians')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "背景误判率 99.57 %:（ 12945 / 13001 ）  对象误判率 0.03 %:（ 4 / 15123 ）\n",
      "28124 个测试样本中错误 12949 个，错误率为 46.04 %.\n",
      "背景误判率 99.79 %:（ 486 / 487 ）  对象误判率 0.0 %:（ 0 / 537 ）\n",
      "1024 个测试样本中错误 486 个，错误率为 47.46 %.\n"
     ]
    }
   ],
   "source": [
    "para=parameter()\n",
    "NN=NeuralNetwork(para)\n",
    "error=error_test(NN,train_x.T,train_y.T,para)\n",
    "error=error_test(NN,test_x.T,test_y.T,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练第  1  轮,每轮  7031 批\n",
      "已完成 1 / 10  本轮用时 70.55 秒\n",
      "背景误判率 7.39 %:（ 36 / 487 ）  对象误判率 11.36 %:（ 61 / 537 ）\n",
      "1024 个测试样本中错误 97 个，错误率为 9.47 %.\n",
      "开始训练第  2  轮,每轮  7031 批\n",
      "已完成 2 / 10  本轮用时 72.07 秒\n",
      "背景误判率 5.75 %:（ 28 / 487 ）  对象误判率 9.5 %:（ 51 / 537 ）\n",
      "1024 个测试样本中错误 79 个，错误率为 7.71 %.\n",
      "开始训练第  3  轮,每轮  7031 批\n",
      "已完成 3 / 10  本轮用时 71.61 秒\n",
      "背景误判率 4.72 %:（ 23 / 487 ）  对象误判率 8.38 %:（ 45 / 537 ）\n",
      "1024 个测试样本中错误 68 个，错误率为 6.64 %.\n",
      "开始训练第  4  轮,每轮  7031 批\n",
      "已完成 4 / 10  本轮用时 71.26 秒\n",
      "背景误判率 4.31 %:（ 21 / 487 ）  对象误判率 5.96 %:（ 32 / 537 ）\n",
      "1024 个测试样本中错误 53 个，错误率为 5.18 %.\n",
      "开始训练第  5  轮,每轮  7031 批\n",
      "已完成 5 / 10  本轮用时 71.49 秒\n",
      "背景误判率 4.31 %:（ 21 / 487 ）  对象误判率 6.15 %:（ 33 / 537 ）\n",
      "1024 个测试样本中错误 54 个，错误率为 5.27 %.\n",
      "开始训练第  6  轮,每轮  7031 批\n",
      "已完成 6 / 10  本轮用时 75.07 秒\n",
      "背景误判率 3.9 %:（ 19 / 487 ）  对象误判率 6.15 %:（ 33 / 537 ）\n",
      "1024 个测试样本中错误 52 个，错误率为 5.08 %.\n",
      "开始训练第  7  轮,每轮  7031 批\n",
      "已完成 7 / 10  本轮用时 71.84 秒\n",
      "背景误判率 3.7 %:（ 18 / 487 ）  对象误判率 4.84 %:（ 26 / 537 ）\n",
      "1024 个测试样本中错误 44 个，错误率为 4.3 %.\n",
      "开始训练第  8  轮,每轮  7031 批\n",
      "已完成 8 / 10  本轮用时 67.31 秒\n",
      "背景误判率 3.9 %:（ 19 / 487 ）  对象误判率 4.84 %:（ 26 / 537 ）\n",
      "1024 个测试样本中错误 45 个，错误率为 4.39 %.\n",
      "开始训练第  9  轮,每轮  7031 批\n",
      "已完成 9 / 10  本轮用时 67.31 秒\n",
      "背景误判率 3.7 %:（ 18 / 487 ）  对象误判率 4.84 %:（ 26 / 537 ）\n",
      "1024 个测试样本中错误 44 个，错误率为 4.3 %.\n",
      "开始训练第  10  轮,每轮  7031 批\n",
      "已完成 10 / 10  本轮用时 65.93 秒\n",
      "背景误判率 3.49 %:（ 17 / 487 ）  对象误判率 4.1 %:（ 22 / 537 ）\n",
      "1024 个测试样本中错误 39 个，错误率为 3.81 %.\n",
      "背景误判率 4.35 %:（ 566 / 13001 ）  对象误判率 4.67 %:（ 706 / 15123 ）\n",
      "28124 个测试样本中错误 1272 个，错误率为 4.52 %.\n"
     ]
    }
   ],
   "source": [
    "NN=train(NN,train_x.T,train_y.T,test_x.T,test_y.T,para)\n",
    "e=error_test(NN,train_x.T,train_y.T,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功\n"
     ]
    }
   ],
   "source": [
    "savenn(NN,'NNr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN=loadnn('NNr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "背景误判率 58.18 %:（ 32 / 55 ）  对象误判率 2.22 %:（ 1 / 45 ）\n",
      "100 个测试样本中错误 33 个，错误率为 33.0 %.\n",
      "背景误判率 59.1 %:（ 263 / 445 ）  对象误判率 2.58 %:（ 13 / 503 ）\n",
      "948 个测试样本中错误 276 个，错误率为 29.11 %.\n",
      "开始训练第  1  轮,每轮  237 批\n",
      "已完成 1 / 1  本轮用时 2.32 秒\n",
      "背景误判率 30.91 %:（ 17 / 55 ）  对象误判率 22.22 %:（ 10 / 45 ）\n",
      "100 个测试样本中错误 27 个，错误率为 27.0 %.\n",
      "背景误判率 30.56 %:（ 136 / 445 ）  对象误判率 14.91 %:（ 75 / 503 ）\n",
      "948 个测试样本中错误 211 个，错误率为 22.26 %.\n"
     ]
    }
   ],
   "source": [
    "#用于再训练\n",
    "para=parameter()\n",
    "para.epoch=1\n",
    "para.learning_rate=0.001\n",
    "\n",
    "error=error_test(NN,test_x.T,test_y.T,para)\n",
    "error=error_test(NN,train_x.T,train_y.T,para)\n",
    "\n",
    "NN=train(NN,train_x.T,train_y.T,test_x.T,test_y.T,para)\n",
    "e=error_test(NN,train_x.T,train_y.T,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集合划分完成\n"
     ]
    }
   ],
   "source": [
    "#开始训练车的分类器\n",
    "[train_x,train_y,test_x,test_y]=obtain_car_train_set('./data/cars','./data/background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "背景误判率 95.73 %:（ 426 / 445 ）  对象误判率 3.78 %:（ 19 / 503 ）\n",
      "948 个测试样本中错误 445 个，错误率为 46.94 %.\n",
      "背景误判率 94.55 %:（ 52 / 55 ）  对象误判率 6.67 %:（ 3 / 45 ）\n",
      "100 个测试样本中错误 55 个，错误率为 55.0 %.\n"
     ]
    }
   ],
   "source": [
    "para=parameter()\n",
    "para.layer=2\n",
    "para.layer_nodes=[512,1]\n",
    "para.learning_rate=0.01\n",
    "para.activation_function_name='leaky_ReLU'\n",
    "para.epoch=3\n",
    "para.batchsize=4\n",
    "b=NeuralNetwork(para)\n",
    "error=error_test(b,train_x.T,train_y.T,para)\n",
    "error=error_test(b,test_x.T,test_y.T,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练第  1  轮,每轮  237 批\n",
      "已完成 1 / 3  本轮用时 4.13 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "开始训练第  2  轮,每轮  237 批\n",
      "已完成 2 / 3  本轮用时 4.87 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "开始训练第  3  轮,每轮  237 批\n",
      "已完成 3 / 3  本轮用时 6.18 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "背景误判率 5.84 %:（ 26 / 445 ）  对象误判率 15.71 %:（ 79 / 503 ）\n",
      "948 个测试样本中错误 105 个，错误率为 11.08 %.\n"
     ]
    }
   ],
   "source": [
    "b=train(b,train_x.T,train_y.T,test_x.T,test_y.T,para)\n",
    "e=error_test(b,train_x.T,train_y.T,para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功\n",
      "开始训练第  1  轮,每轮  237 批\n",
      "已完成 1 / 3  本轮用时 4.17 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "开始训练第  2  轮,每轮  237 批\n",
      "已完成 2 / 3  本轮用时 4.88 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "开始训练第  3  轮,每轮  237 批\n",
      "已完成 3 / 3  本轮用时 4.83 秒\n",
      "背景误判率 0.0 %:（ 0 / 55 ）  对象误判率 13.33 %:（ 6 / 45 ）\n",
      "100 个测试样本中错误 6 个，错误率为 6.0 %.\n",
      "背景误判率 5.39 %:（ 24 / 445 ）  对象误判率 15.31 %:（ 77 / 503 ）\n",
      "948 个测试样本中错误 101 个，错误率为 10.65 %.\n"
     ]
    }
   ],
   "source": [
    "savenn(b,'NNc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
